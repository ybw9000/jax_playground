{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyO1ZMdLa4ngCWf31zIoPiaV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ybw9000/jax_playground/blob/main/jax_pmap_shard_map_and_jit_inshardings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "fyDbf0Nq6Swl"
      },
      "outputs": [],
      "source": [
        "import jax\n",
        "import jax.numpy as jnp\n",
        "import jax.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "devices = jax.devices()\n",
        "devices"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcT_U-Tq_YS_",
        "outputId": "9cdeffae-c3ac-4882-cf63-2accca63ea5c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# would error out if there are less than 7 XLA devices\n",
        "result = jax.pmap(lambda x: x ** 2)(jnp.arange(8))\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IQ8Qt6qeZgLT",
        "outputId": "2b26a984-1bb1-4d12-a630-55c5fd392447"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0  1  4  9 16 25 36]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import make_jaxpr\n",
        "\n",
        "def f(x, y):\n",
        "  a = jnp.dot(x, y)\n",
        "  b = jnp.tanh(a)\n",
        "  return b\n",
        "\n",
        "xs = jnp.ones((8, 2, 3))\n",
        "ys = jnp.ones((8, 3, 4))\n",
        "\n",
        "# 2D dot general aka gemm\n",
        "print(\"f jaxpr\")\n",
        "print(make_jaxpr(f)(xs[0], ys[0]))\n",
        "\n",
        "# 3D dot general aka BMM\n",
        "print(\"vmap(f) jaxpr\")\n",
        "print(make_jaxpr(jax.vmap(f))(xs, ys))\n",
        "\n",
        "# 2D dot general nested in a xla_pmap\n",
        "print(\"pmap(f) jaxpr\")\n",
        "print(make_jaxpr(jax.pmap(f))(xs, ys))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ictFgSC6ZvPO",
        "outputId": "b7f4cd90-ac0d-4bfe-c92f-e0f7c8a73a3e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f jaxpr\n",
            "{ lambda ; a:f32[2,3] b:f32[3,4]. let\n",
            "    c:f32[2,4] = dot_general[\n",
            "      dimension_numbers=(([1], [0]), ([], []))\n",
            "      preferred_element_type=float32\n",
            "    ] a b\n",
            "    d:f32[2,4] = tanh c\n",
            "  in (d,) }\n",
            "vmap(f) jaxpr\n",
            "{ lambda ; a:f32[8,2,3] b:f32[8,3,4]. let\n",
            "    c:f32[8,2,4] = dot_general[\n",
            "      dimension_numbers=(([2], [1]), ([0], [0]))\n",
            "      preferred_element_type=float32\n",
            "    ] a b\n",
            "    d:f32[8,2,4] = tanh c\n",
            "  in (d,) }\n",
            "pmap(f) jaxpr\n",
            "{ lambda ; a:f32[8,2,3] b:f32[8,3,4]. let\n",
            "    c:f32[8,2,4] = xla_pmap[\n",
            "      axis_name=<axis 0x7968e03cdbd0>\n",
            "      axis_size=8\n",
            "      backend=None\n",
            "      call_jaxpr={ lambda ; d:f32[2,3] e:f32[3,4]. let\n",
            "          f:f32[2,4] = dot_general[\n",
            "            dimension_numbers=(([1], [0]), ([], []))\n",
            "            preferred_element_type=float32\n",
            "          ] d e\n",
            "          g:f32[2,4] = tanh f\n",
            "        in (g,) }\n",
            "      devices=None\n",
            "      donated_invars=(False, False)\n",
            "      global_axis_size=8\n",
            "      in_axes=(0, 0)\n",
            "      is_explicit_global_axis_size=False\n",
            "      name=f\n",
            "      out_axes=(0,)\n",
            "    ] a b\n",
            "  in (c,) }\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = jax.pmap(lambda x: x ** 2)(jnp.arange(8))\n",
        "z = result / 2\n",
        "print(z)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E92L-pstaDws",
        "outputId": "5b59d27f-eec0-4231-c4e0-f9be830faa7e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.   0.5  2.   4.5  8.  12.5 18.  24.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sharded over multiple devices\n",
        "result.sharding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pW2vX6IobH_F",
        "outputId": "c104c889-e974-4772-cb0e-c98616add629"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PmapSharding(sharding_spec=ShardingSpec((Unstacked(8),), (ShardedAxis(axis=0),)), devices=[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0)\n",
              " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1)\n",
              " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0)\n",
              " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1)\n",
              " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0)\n",
              " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1)\n",
              " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0)\n",
              " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# moved back to device 0 as result / 2 is not a sharded operation\n",
        "z.sharding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtj58uy8bhj6",
        "outputId": "48b97adf-3d72-4d4b-ad7e-321943c2ce79"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SingleDeviceSharding(device=TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), memory_kind=device)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.global_shards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uq02qmE3bqKu",
        "outputId": "9773eb75-0813-44d6-84cd-1a91a4fcac53"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Shard(device=TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), index=(0,), replica_id=0, data=0),\n",
              " Shard(device=TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1), index=(1,), replica_id=0, data=1),\n",
              " Shard(device=TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0), index=(2,), replica_id=0, data=4),\n",
              " Shard(device=TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1), index=(3,), replica_id=0, data=9),\n",
              " Shard(device=TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0), index=(4,), replica_id=0, data=16),\n",
              " Shard(device=TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1), index=(5,), replica_id=0, data=25),\n",
              " Shard(device=TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0), index=(6,), replica_id=0, data=36),\n",
              " Shard(device=TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1), index=(7,), replica_id=0, data=49)]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# can not use jnp apis on each shard directly\n",
        "type(result.global_shards[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "-MSGuKY8cssb",
        "outputId": "0a5f7b3e-e722-4382-af7b-8e85498d3c62"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "jax._src.array.Shard"
            ],
            "text/html": [
              "<div style=\"max-width:800px; border: 1px solid var(--colab-border-color);\"><style>\n",
              "      pre.function-repr-contents {\n",
              "        overflow-x: auto;\n",
              "        padding: 8px 12px;\n",
              "        max-height: 500px;\n",
              "      }\n",
              "\n",
              "      pre.function-repr-contents.function-repr-contents-collapsed {\n",
              "        cursor: pointer;\n",
              "        max-height: 100px;\n",
              "      }\n",
              "    </style>\n",
              "    <pre style=\"white-space: initial; background:\n",
              "         var(--colab-secondary-surface-color); padding: 8px 12px;\n",
              "         border-bottom: 1px solid var(--colab-border-color);\"><b>jax._src.array.Shard</b><br/>def __init__(device: Device, sharding: Sharding, global_shape: Shape, data: None | ArrayImpl | PRNGKeyArray=None)</pre><pre class=\"function-repr-contents function-repr-contents-collapsed\" style=\"\"><a class=\"filepath\" style=\"display:none\" href=\"#\">/usr/local/lib/python3.10/dist-packages/jax/_src/array.py</a>A single data shard of an Array.\n",
              "\n",
              "Attributes:\n",
              "  device : Which device this shard resides on.\n",
              "  index : The index into the global array of this shard.\n",
              "  replica_id : Integer id indicating which replica of the global array this\n",
              "    shard is part of. Always 0 for fully sharded data\n",
              "    (i.e. when thereâ€™s only 1 replica).\n",
              "  data : The data of this shard. None if ``device`` is non-local.</pre>\n",
              "      <script>\n",
              "      if (google.colab.kernel.accessAllowed && google.colab.files && google.colab.files.view) {\n",
              "        for (const element of document.querySelectorAll('.filepath')) {\n",
              "          element.style.display = 'block'\n",
              "          element.onclick = (event) => {\n",
              "            event.preventDefault();\n",
              "            event.stopPropagation();\n",
              "            google.colab.files.view(element.textContent, 62);\n",
              "          };\n",
              "        }\n",
              "      }\n",
              "      for (const element of document.querySelectorAll('.function-repr-contents')) {\n",
              "        element.onclick = (event) => {\n",
              "          event.preventDefault();\n",
              "          event.stopPropagation();\n",
              "          element.classList.toggle('function-repr-contents-collapsed');\n",
              "        };\n",
              "      }\n",
              "      </script>\n",
              "      </div>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_sharded = jax.pmap(lambda x: x / 2)(result)"
      ],
      "metadata": {
        "id": "QmluEJ5Qd2LV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# same value but different layout\n",
        "print(z_sharded)\n",
        "print(z_sharded.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c2idQZ5ZeOMW",
        "outputId": "39e5d3f1-4023-450d-f181-b3cecc93bc16"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.   0.5  2.   4.5  8.  12.5 18.  24.5]\n",
            "PmapSharding(sharding_spec=ShardingSpec((Unstacked(8),), (ShardedAxis(axis=0),)), device_ids=[0, 1, 2, 3, 4, 5, 6, 7], device_platform=TPU, device_shape=(8,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import random\n",
        "\n",
        "# create 8 random keys\n",
        "keys = random.split(random.key(0), 8)\n",
        "# create a 5000 x 6000 matrix on each device by mapping over keys\n",
        "mats = jax.pmap(lambda key: random.normal(key, (128, 256)))(keys)\n",
        "# the stack of matrices is represented logically as a single array\n",
        "print(mats.shape)\n",
        "print(mats.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fup5YhGfeWPy",
        "outputId": "c5edfecc-926f-4a81-fc2b-a094ff2a8445"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 128, 256)\n",
            "PmapSharding(sharding_spec=ShardingSpec((Unstacked(8), NoSharding(), NoSharding()), (ShardedAxis(axis=0),)), device_ids=[0, 1, 2, 3, 4, 5, 6, 7], device_platform=TPU, device_shape=(8,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run a local matmul on each device in parallel (no data transfer)\n",
        "result = jax.pmap(lambda x: jnp.matmul(x, x.T))(mats)\n",
        "result.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PmNzlHfe1Zx",
        "outputId": "df1226ee-17d3-458e-94f4-9e3c46ee1d72"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8, 128, 128)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# only one scalar per device was pulled back to the host\n",
        "res = jax.pmap(jnp.sum)(result)\n",
        "print(res, res.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7gBbu9YfjSI",
        "outputId": "f8f6684d-2b18-4b4f-8112-bfbb49032c73"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[33369.695 33508.656 33175.78  32662.605 31562.873 32247.285 35248.633\n",
            " 30591.709] PmapSharding(sharding_spec=ShardingSpec((Unstacked(8),), (ShardedAxis(axis=0),)), device_ids=[0, 1, 2, 3, 4, 5, 6, 7], device_platform=TPU, device_shape=(8,))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# all reduce with psum\n",
        "from jax import lax\n",
        "\n",
        "def all_reduce(x):\n",
        "  return lax.psum(x, 'k')\n",
        "\n",
        "x = jax.pmap(lambda key: random.normal(key, (2, 4)))(keys)\n",
        "y = jax.pmap(all_reduce, axis_name='k')(x)\n",
        "single_device_y = jnp.sum(x, axis=0)\n",
        "# all reduce so each the shape of y is still 3D aka 8, 2, 4\n",
        "print(y.shape, single_device_y.shape)\n",
        "# value should match\n",
        "print(y[0], single_device_y)\n",
        "print(jnp.allclose(y[0], single_device_y))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3-B3eu9SftV0",
        "outputId": "100642d7-6b91-4cbf-9e40-3a35c2f0a79a"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8, 2, 4) (2, 4)\n",
            "[[-0.8284544  -4.95767     0.55136424 -2.3609824 ]\n",
            " [-0.40268528  1.9361467  -4.852154   -1.8133668 ]] [[-0.8284545  -4.95767     0.5513642  -2.3609827 ]\n",
            " [-0.40268534  1.9361467  -4.852154   -1.813367  ]]\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jax import random\n",
        "from jax import lax\n",
        "\n",
        "# let's work on a gemm K shard\n",
        "def gemm_kshard(x, y):\n",
        "  z = jnp.matmul(x, y)\n",
        "  print(z)\n",
        "  return lax.psum(z, 'i')\n",
        "\n",
        "keys = random.split(random.key(0), 8)\n",
        "x = jax.pmap(lambda key: random.normal(key, (2, 4)))(keys)\n",
        "y = jax.pmap(lambda key: random.normal(key, (4, 2)))(keys)\n",
        "z = jax.pmap(gemm_kshard, axis_name='i')(x, y)\n",
        "print(z.sharding, z.shape)\n",
        "x_0 = x.transpose(1, 0, 2).reshape(x.shape[1], -1)\n",
        "y_0 = y.reshape(-1, y.shape[-1])\n",
        "print(x_0.sharding, y_0.sharding)\n",
        "z_0 = jnp.matmul(x_0, y_0)\n",
        "print(jnp.allclose(z[0], z_0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GHEaO1bKh5j2",
        "outputId": "901a2ecf-7321-4990-d906-ad44c072e1d9"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traced<ShapedArray(float32[2,2])>with<DynamicJaxprTrace(level=0/1)>\n",
            "PmapSharding(sharding_spec=ShardingSpec((Unstacked(8), NoSharding(), NoSharding()), (ShardedAxis(axis=0),)), device_ids=[0, 1, 2, 3, 4, 5, 6, 7], device_platform=TPU, device_shape=(8,)) (8, 2, 2)\n",
            "SingleDeviceSharding(device=TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), memory_kind=device) SingleDeviceSharding(device=TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), memory_kind=device)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.sharding import Mesh, PartitionSpec as P, NamedSharding\n",
        "from jax.experimental.shard_map import shard_map\n",
        "from functools import partial\n",
        "\n",
        "mesh = Mesh(devices, ('k',))\n",
        "\n",
        "@partial(shard_map, mesh=mesh, in_specs=(P(None, 'k'), P('k', None)), out_specs=P(None, None))\n",
        "def gemm_shard_map(x, y):\n",
        "  z = jnp.matmul(x, y)\n",
        "  return lax.psum(z, 'k')\n",
        "\n",
        "z_shard = gemm_shard_map(x_0, y_0)\n",
        "print(z_shard.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sHbfyllUr04g",
        "outputId": "b72b29fc-1802-4dc7-9af4-34e76795bd8c"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NamedSharding(mesh=Mesh('k': 8), spec=PartitionSpec(), memory_kind=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z_shard.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v6UlfyfAPnBO",
        "outputId": "24e78b40-4155-4b8b-a3ca-31aff1a64d3a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(jnp.allclose(z_shard, z_0))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqbHZKBOQbrw",
        "outputId": "6267b469-fe7c-4a06-8ffe-dac6010e4afa"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@partial(shard_map, mesh=mesh, in_specs=(P(None, 'k'), P('k', None)), out_specs=P('k', None))\n",
        "def gemm_reduce_scatter(x, y):\n",
        "  z = jnp.matmul(x, y)\n",
        "  return lax.psum_scatter(z, axis_name='k', scatter_dimension=0)\n",
        "\n",
        "x = random.normal(keys[0], (8, 16))\n",
        "y = random.normal(keys[0], (16, 2))\n",
        "z = gemm_reduce_scatter(x, y)\n",
        "print(z.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JAXllpyRQlwA",
        "outputId": "af8a231a-d047-4107-d880-8929a854a67b"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NamedSharding(mesh=Mesh('k': 8), spec=PartitionSpec('k',), memory_kind=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OOniuNtvRhqd",
        "outputId": "b447553e-97d9-411c-f803-020d11336bc6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(16,)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check_rep has to be False otherwise it is legalizing against input is shard yet output is not sharded\n",
        "@partial(shard_map, mesh=mesh, in_specs=(P(None, 'k'), P('k', None)), out_specs=P(None, None), check_rep=False)\n",
        "def gemm_all_reduce(x, y):\n",
        "  z = jnp.matmul(x, y)\n",
        "  z_rs = lax.psum_scatter(z, axis_name='k', scatter_dimension=0)\n",
        "  z_ag = lax.all_gather(z_rs, axis_name='k', axis=0)\n",
        "  return z_ag\n",
        "\n",
        "x = random.normal(keys[0], (8, 16))\n",
        "y = random.normal(keys[0], (16, 2))\n",
        "z = gemm_all_reduce(x, y)\n",
        "print(z.sharding)\n",
        "z_psum = gemm_shard_map(x, y)\n",
        "print(z_psum.sharding)\n",
        "print(jnp.allclose(z, z_psum))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84Tpz_XxR1PU",
        "outputId": "ab74b738-9585-40b2-d134-271c6e0e7e73"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NamedSharding(mesh=Mesh('k': 8), spec=PartitionSpec(), memory_kind=device)\n",
            "NamedSharding(mesh=Mesh('k': 8), spec=PartitionSpec(), memory_kind=device)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def qkv(x, q, k, v, num_heads=8):\n",
        "    # x: S, K\n",
        "    # Q, K, V: K, M\n",
        "    x_q = jnp.matmul(x, q).reshape(x.shape[0], num_heads, -1).transpose(1, 0, 2)  # S, M -> S, H, E -> H, S, E\n",
        "    x_k = jnp.matmul(x, k).reshape(x.shape[0], num_heads, -1).transpose(1, 0, 2)  # S, M -> S, H, E -> H, S, E\n",
        "    x_v = jnp.matmul(x, v).reshape(x.shape[0], num_heads, -1).transpose(1, 0, 2)  # S, M -> S, H, E -> H, S, E\n",
        "    return x_q, x_k, x_v\n",
        "\n",
        "def attention(q, k, v, proj):\n",
        "    k_t = k.transpose(0, 2, 1)  # H, S, E -> H, E, S\n",
        "    qk = jnp.matmul(q, k_t)  # H, S, S\n",
        "    qk = qk / jnp.sqrt(q.shape[-1])\n",
        "    qk = jax.nn.softmax(qk, axis=-1)\n",
        "    mm1 = jnp.matmul(qk, v)  # H, S, E\n",
        "    head_fuse = mm1.transpose(1, 0, 2).reshape(x.shape[0], -1)  # S, H, E -> S, E*H\n",
        "    proj_out = jnp.matmul(head_fuse, proj)\n",
        "    return proj_out\n",
        "\n",
        "def mlp(up, down, x):\n",
        "    out = jnp.matmul(x, up)\n",
        "    out = jax.nn.gelu(out)\n",
        "    out = jnp.matmul(out, down)\n",
        "    return out\n",
        "\n",
        "def transformer_layer(x, q, k, v, proj, up, down):\n",
        "    x_q, x_k, x_v = qkv(x, q, k, v)\n",
        "    out = attention(x_q, x_k, x_v, x, proj) + x\n",
        "    out = mlp(up, down, out) + out\n",
        "    return out"
      ],
      "metadata": {
        "id": "GEJ7FElBSp6Z"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = random.normal(keys[0], (128, 1024))\n",
        "q = random.normal(keys[1], (1024, 1024)) / jnp.sqrt(1024)\n",
        "k = random.normal(keys[2], (1024, 1024)) / jnp.sqrt(1024)\n",
        "v = random.normal(keys[3], (1024, 1024)) / jnp.sqrt(1024)\n",
        "proj = random.normal(keys[4], (1024, 1024)) / jnp.sqrt(1024)\n",
        "up = random.normal(keys[5], (1024, 4096)) / jnp.sqrt(1024)\n",
        "down = random.normal(keys[6], (4096, 1024)) / jnp.sqrt(4096)"
      ],
      "metadata": {
        "id": "hoS560j9Xg2o"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = transformer_layer(x, q, k, v, proj, up, down)\n",
        "print(out.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AL8BKJ3GYH-o",
        "outputId": "48f87f2a-3b37-46bb-968c-765823464e0d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SingleDeviceSharding(device=TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0), memory_kind=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "in_shardings = (\n",
        "    jax.sharding.NamedSharding(mesh, P(None, None)),  # x\n",
        "    jax.sharding.NamedSharding(mesh, P(None, 'k')),  # q\n",
        "    jax.sharding.NamedSharding(mesh, P(None, 'k')),  # k\n",
        "    jax.sharding.NamedSharding(mesh, P(None, 'k')),  # v\n",
        "    jax.sharding.NamedSharding(mesh, P('k', None)),  # proj\n",
        "    jax.sharding.NamedSharding(mesh, P(None, 'k')),  # up\n",
        "    jax.sharding.NamedSharding(mesh, P('k', None))   # down\n",
        ")\n",
        "transformer_layer_gspmd = jax.jit(transformer_layer, in_shardings=in_shardings)"
      ],
      "metadata": {
        "id": "8U8RhozoYOd5"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_gspmd = transformer_layer_gspmd(x, q, k, v, proj, up, down)\n",
        "print(out_gspmd.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPphRXziaNrg",
        "outputId": "e33e4995-bb22-43fb-f391-58a9ce6dc26e"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NamedSharding(mesh=Mesh('k': 8), spec=PartitionSpec(None, None), memory_kind=device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out_gspmd.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m1Osx3F_aQdm",
        "outputId": "49cf5dc7-2d2d-4bc6-d709-06d3180f483e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "out.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYF9ziYRcyIf",
        "outputId": "4e096ff8-a6ce-468c-d6f6-79def14b7f9a"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(128, 1024)"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(jnp.allclose(out, out_gspmd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ChqCuHNc0H-",
        "outputId": "9d7d813b-b7f9-48a4-f78e-d728993e5704"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(jnp.allclose(out[:, 0], out_gspmd[:, 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "luQcxiB0c2nZ",
        "outputId": "a25fe0ab-717a-404e-9e10-9a3306472aa2"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(jnp.allclose(out[0, :128], out_gspmd[0, :128]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lzsZL08Kc6WZ",
        "outputId": "98aee65c-c469-4506-b029-b8b644dc0258"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_sharded = jax.device_put(x, NamedSharding(mesh, P(None, None)))\n",
        "q_sharded = jax.device_put(q,  NamedSharding(mesh, P(None, 'k')))\n",
        "k_sharded = jax.device_put(k,  NamedSharding(mesh, P(None, 'k')))\n",
        "v_sharded = jax.device_put(v,  NamedSharding(mesh, P(None, 'k')))\n",
        "proj_sharded = jax.device_put(proj,  NamedSharding(mesh, P('k', None)))\n",
        "up_sharded = jax.device_put(up,  NamedSharding(mesh, P(None, 'k')))\n",
        "down_sharded = jax.device_put(down,  NamedSharding(mesh, P('k', None)))"
      ],
      "metadata": {
        "id": "XduUV1yPc8qW"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_gspmd_sharded_input = jax.jit(transformer_layer)(x_sharded, q_sharded, k_sharded, v_sharded, proj_sharded, up_sharded, down_sharded)"
      ],
      "metadata": {
        "id": "nsAlE3ExeWZ2"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(jnp.allclose(out_gspmd, out_gspmd_sharded_input))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N9su26Hhe3eP",
        "outputId": "13c8ba00-7cee-41dc-edd3-00c1643ab970"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qkv_manual_shard = shard_map(qkv, mesh, in_specs=(P(None, None), P(None, 'k'), P(None, 'k'), P(None, 'k')), out_specs=(P('k', None, None)) * 3)\n",
        "\n",
        "@partial(shard_map, mesh=mesh, in_specs=(P('k', None, None)) * 3 + (P('k', None)), out_specs=P(None, None))\n",
        "def attention_manual_shard(q, k, v proj):\n",
        "    out = attention(q, k, v, proj)\n",
        "    return lax.psum(out, 'k')\n",
        "\n",
        "\n",
        "@partial(shard_map, mesh=mesh, in_specs=(P(None, 'k'), P('k', None), P(None, None)), out_specs=P(None, None))\n",
        "def mlp_manual_shard(up, down, x):\n",
        "    out = jnp.matmul(x, up)\n",
        "    out = jax.nn.gelu(out)\n",
        "    out = jnp.matmul(out, down)\n",
        "    return out\n",
        "\n",
        "def transformer_layer_manual_shard(x, q, k, v, proj, up, down):\n",
        "    x_q, x_k, x_v = qkv_manual_shard(x, q, k, v)\n",
        "    out = mlp_manual_shard(x_q, x_k, x_v, x, proj) + x\n",
        "    out = mlp_manual_shard(up, down, out) + out\n",
        "    return out\n",
        ""
      ],
      "metadata": {
        "id": "v8dWPxq_e8ZP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out_manual_shard = transformer_layer_manual_shard(x_sharded, q_sharded, k_sharded, v_sharded, proj_sharded, up_sharded, down_sharded)\n",
        "print(jnp.allclose(out_gspmd, out_manual_shard))"
      ],
      "metadata": {
        "id": "zx5pSumOh9bG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}